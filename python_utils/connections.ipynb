{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "#import sys\n",
    "log = logging.getLogger(__name__)\n",
    "log.debug('Module loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Connection\n",
    "\n",
    "Usage :\n",
    "```\n",
    "query = 'SELECT 1'\n",
    "sql_query(query, creds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_conn(creds, server='CHCXSQLARMDM008', db='Pricing'):\n",
    "    # Import in function to avoid useless dependecies for project that doesnt use SQL\n",
    "    import pymssql\n",
    "    return pymssql.connect(server, \n",
    "                           creds['AD']['domain']+'\\\\'+creds['AD']['user'], \n",
    "                           creds['AD']['pass'], \n",
    "                           db, \n",
    "                           autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_query(query, creds, method='execute', server='CHCXSQLARMDM008', db='Pricing'):\n",
    "    log.debug(f'SQL : About to launch query {query}')\n",
    "    \n",
    "    connection = get_sql_conn(creds, server, db)\n",
    "    log.debug('Connected to SQL. Executing query... (please wait)')\n",
    "    if 'execute'==method :\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        cursor.close()\n",
    "    elif 'pandas.read'==method :\n",
    "        data = pd.read_sql(query, connection)\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "    \n",
    "    log.debug(f'Done ! (and connection closed)')\n",
    "    if 'pandas.read'==method :\n",
    "        return data\n",
    "    else :\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive Connection\n",
    "\n",
    "Usage :\n",
    "```\n",
    "query = 'SELECT 1'\n",
    "hive_query(query, creds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hive_conn(creds, server='hiveserver2.idx.expedmz.com', port=10001, db=\"lz\") :\n",
    "    # Import in function to avoid useless dependecies for project that doesnt use Hive)\n",
    "    from impala.dbapi import connect # To connect to Hive \n",
    "    \n",
    "    return connect(host=server, port=port, \n",
    "                    database=db, auth_mechanism=\"PLAIN\", \n",
    "                    user=creds['HiveServer2']['user'], password=creds['HiveServer2']['pass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hive_query(query, creds, method='execute', server='hiveserver2.idx.expedmz.com', port=10001, db=\"lz\") :\n",
    "    log.debug(f'Hive : About to launch query {query}')\n",
    "    \n",
    "    connection = get_hive_conn(creds, server, port, db)\n",
    "    log.debug('Connected to Hive. Executing query... (please wait)')\n",
    "    if 'execute'==method :\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        cursor.close()\n",
    "    elif 'pandas.read'==method :\n",
    "        data = pd.read_sql(query, connection)\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "    \n",
    "    log.debug(f'Done ! (and connection closed)')\n",
    "    if 'pandas.read'==method :\n",
    "        return data\n",
    "    else :\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Connection and S3 helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_s3(df, s3_key, s3_bucket='arm-ro-lz', fmt='parquet', engine='pyarrow', compression='snappy') :\n",
    "    import boto3\n",
    "    import os\n",
    "    \n",
    "    filename_suffix = f'.{compression}.{fmt}' if fmt=='parquet' else f'.{fmt}'\n",
    "    \n",
    "    temp_filename  = s3_key.split('/')[-1]\n",
    "    temp_filename += filename_suffix\n",
    "    local_path = f\"./tmp/{temp_filename}\"\n",
    "    if not os.path.exists(os.path.dirname(local_path)):\n",
    "        os.makedirs(os.path.dirname(local_path))\n",
    "        \n",
    "    if fmt=='parquet' :\n",
    "        df.to_parquet(local_path, engine=engine, compression=compression)\n",
    "    elif fmt=='csv' :\n",
    "        df.to_csv(local_path)\n",
    "        \n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.meta.client.upload_file(local_path, s3_bucket, s3_key+filename_suffix)\n",
    "    log.info(f'{s3_key+filename_suffix} was successfully written !')\n",
    "    #os.remove(local_path)\n",
    "    #log.debug(f'{local_path} has been removed (to be clean)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2",
   "language": "python",
   "name": "python_3.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
